{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit345b259d5ff84ac9983bc7539a960f12",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Loading models trained on shapenet data and saving predicted images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from model import models\n",
    "from model import metrics\n",
    "from data import camera_utils\n",
    "from data import data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global params\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# volume params\n",
    "center = torch.Tensor([0.0, 0.0, 0.0])\n",
    "radius = 1.0\n",
    "vol_params = (\"sphere\", center, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# load saved model\n",
    "learning_rate = 1e-2\n",
    "input_ch = 6\n",
    "points_type = 'cartesian'\n",
    "viewdir_type = 'cartesian'\n",
    "out_dir = '/home/goel/Thesis/Code/dvr/outputs/shapenet/chair/nomap/'\n",
    "data_dir = '/home/goel/Thesis/Data/shapenet/chair/val'\n",
    "writer_path = os.path.join(out_dir,'logs')\n",
    "model_path = os.path.join(out_dir,'models/2000.pth')\n",
    "\n",
    "# create the model\n",
    "model = models.ConvNet(input_ch=input_ch, output_ch=3).to(device)\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "input_map = checkpoint['input_map']\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = []\n",
    "\n",
    "for cam_file in sorted(glob.glob(data_dir + \"/*.json\")):\n",
    "    points, viewdirs, valid_mask = data_utils.get_input_data(cam_file, vol_params, points_type, viewdir_type)\n",
    "\n",
    "    input = torch.cat((points, viewdirs),dim=0).to(device)\n",
    "    input = data_utils.input_mapping(input, input_map, True, True, \"cartesian\", \"ConvNet\")\n",
    "\n",
    "    input = input.unsqueeze_(0).to(device)\n",
    "    rgb = model(input)\n",
    "    clamped_rgb = torch.clamp(rgb.detach(), min=0.0, max=1.0)\n",
    "    pred_data.append(clamped_rgb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([25, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.stack(pred_data,dim=0)\n",
    "print(pred.shape)\n",
    "writer = SummaryWriter(writer_path)\n",
    "writer.add_images('val_pred', pred, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_data = []\n",
    "# for img_file in sorted(glob.glob(data_dir + \"/*.jpg\")):\n",
    "#     gt = Image.open(img_file)\n",
    "#     gt = np.array(gt).astype(np.float32) / 255. # shape: (H, W, C)\n",
    "#     gt = torch.Tensor(gt).permute(2,0,1) # shape: (C, H, W)\n",
    "#     gt_data.append(gt)\n",
    "# gt = torch.stack(gt_data,dim=0)\n",
    "# print(gt.shape)\n",
    "# writer.add_images('train_gt', gt, 1)"
   ]
  }
 ]
}